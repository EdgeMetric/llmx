{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmx import  llm, TextGenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TextGenerationConfig( \n",
    "    n=1,\n",
    "    temperature=0.8,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    top_k=50,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    ")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that can explain concepts clearly to a 6 year old child.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is  gravity?\"}\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Providers - OpenAI, PaLM etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravity is like a big invisible force that pulls things towards each other. It's what keeps us on the ground and makes things fall down when we drop them. It's like a big hug from the Earth that keeps us close to it.\n"
     ]
    }
   ],
   "source": [
    "openai_gen = llm(provider=\"openai\")\n",
    "openai_config = TextGenerationConfig(model=\"gpt-3.5-turbo\", use_cache=True)\n",
    "openai_response = openai_gen.generate(messages, config=openai_config)\n",
    "print(openai_response.text[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Service account key file is not set. Please set the PALM_SERVICE_ACCOUNT_KEY_FILE environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/llmx/llmx/utils.py:79\u001b[0m, in \u001b[0;36mget_gcp_credentials\u001b[0;34m(service_account_key_file, scopes)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39m# Attempt to use Application Default Credentials\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39;49mauth\u001b[39m.\u001b[39;49mdefault(scopes\u001b[39m=\u001b[39;49mscopes)\n\u001b[1;32m     80\u001b[0m     auth_req \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39mauth\u001b[39m.\u001b[39mtransport\u001b[39m.\u001b[39mrequests\u001b[39m.\u001b[39mRequest()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/google/auth/_default.py:692\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[39mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 692\u001b[0m \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/victordibia/projects/llmx/notebooks/tutorial.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/victordibia/projects/llmx/notebooks/tutorial.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m palm_gen \u001b[39m=\u001b[39m llm(provider\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpalm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/victordibia/projects/llmx/notebooks/tutorial.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m palm_config \u001b[39m=\u001b[39m TextGenerationConfig(model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcodechat-bison\u001b[39m\u001b[39m\"\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, max_tokens\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, use_cache\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/victordibia/projects/llmx/notebooks/tutorial.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m palm_response \u001b[39m=\u001b[39m palm_gen\u001b[39m.\u001b[39mgenerate(messages, config\u001b[39m=\u001b[39mpalm_config)\n",
      "File \u001b[0;32m~/projects/llmx/llmx/generators/text/textgen.py:10\u001b[0m, in \u001b[0;36mllm\u001b[0;34m(provider, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m OpenAITextGenerator(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m      9\u001b[0m \u001b[39melif\u001b[39;00m provider\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpalm\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m provider\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgoogle\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m PalmTextGenerator(provider\u001b[39m=\u001b[39;49mprovider, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     11\u001b[0m \u001b[39melif\u001b[39;00m provider\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcohere\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m CohereTextGenerator(provider\u001b[39m=\u001b[39mprovider, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/llmx/llmx/generators/text/palm_textgen.py:22\u001b[0m, in \u001b[0;36mPalmTextGenerator.__init__\u001b[0;34m(self, palm_key_file, project_id, project_location, provider)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject_id \u001b[39m=\u001b[39m project_id\n\u001b[1;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject_location \u001b[39m=\u001b[39m project_location\n\u001b[0;32m---> 22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcredentials \u001b[39m=\u001b[39m get_gcp_credentials(palm_key_file)\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_list \u001b[39m=\u001b[39m providers[provider][\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m provider \u001b[39min\u001b[39;00m providers \u001b[39melse\u001b[39;00m {}\n",
      "File \u001b[0;32m~/projects/llmx/llmx/utils.py:86\u001b[0m, in \u001b[0;36mget_gcp_credentials\u001b[0;34m(service_account_key_file, scopes)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mexcept\u001b[39;00m google\u001b[39m.\u001b[39mauth\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mDefaultCredentialsError:\n\u001b[1;32m     84\u001b[0m     \u001b[39m# Fall back to using service account key\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m service_account_key_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     87\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mService account key file is not set. Please set the PALM_SERVICE_ACCOUNT_KEY_FILE environment variable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m     credentials \u001b[39m=\u001b[39m service_account\u001b[39m.\u001b[39mCredentials\u001b[39m.\u001b[39mfrom_service_account_file(\n\u001b[1;32m     90\u001b[0m         service_account_key_file, scopes\u001b[39m=\u001b[39mscopes)\n\u001b[1;32m     91\u001b[0m     auth_req \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39mauth\u001b[39m.\u001b[39mtransport\u001b[39m.\u001b[39mrequests\u001b[39m.\u001b[39mRequest()\n",
      "\u001b[0;31mValueError\u001b[0m: Service account key file is not set. Please set the PALM_SERVICE_ACCOUNT_KEY_FILE environment variable."
     ]
    }
   ],
   "source": [
    "palm_gen = llm(provider=\"palm\")\n",
    "palm_config = TextGenerationConfig(model=\"codechat-bison\", temperature=0, max_tokens=50, use_cache=True)\n",
    "palm_response = palm_gen.generate(messages, config=palm_config)\n",
    "print(palm_response.text[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_gen = llm(provider=\"cohere\")\n",
    "cohere_config = TextGenerationConfig(model=\"command\", max_tokens=4050, use_cache=True)\n",
    "cohere_response = cohere_gen.generate(messages, config=cohere_config)\n",
    "print(cohere_response.text[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_generator = llm(provider=\"hf\", model=\"TheBloke/Llama-2-7b-chat-fp16\", device_map=\"auto\")\n",
    "hf_config = TextGenerationConfig(temperature=0, max_tokens=650, use_cache=False)\n",
    "hf_response = hf_generator.generate(messages, config=hf_config)\n",
    "print(hf_response.text[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
